This project implements an image captioning system using a pretrained BLIP (Bootstrapped Language-Image Pretraining) model from Hugging Face. The model generates natural language descriptions for input images and provides a simple Gradio web interface for interaction.
Features:
  1. Generates captions for input images
  2. Uses pretrained BLIP model
  3. Simple and interactive Gradio UI
Technologies Used:
  a) Python
  b) PyTorch
  c) Hugging Face Transformers
  d) Gradio
  e) PIL (Pillow)
