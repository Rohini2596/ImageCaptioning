This project implements an image captioning system using a pretrained BLIP (Bootstrapped Language-Image Pretraining) model from Hugging Face. The model generates natural language descriptions for input images and provides a simple Gradio web interface for interaction.
Features:
  Generates captions for input images
  Uses pretrained BLIP model
  Simple and interactive Gradio UI
  Easy to run locally
Technologies Used:
  Python
  PyTorch
  Hugging Face Transformers
  Gradio
  PIL (Pillow)
